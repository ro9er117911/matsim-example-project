# MATSim 模擬輸出檔案說明指南

## 概述

當 MATSim 模擬完成後，會在 `scenarios/equil/output/` 目錄產生多個 CSV 統計檔案。這些檔案詳細記錄了代理人的行為變化、交通模式選擇、時間效能等重要指標。

本文件提供每個輸出 CSV 的詳細解釋，幫助你理解模擬結果。

---

## 1. `modestats.csv` - 交通模式選擇統計（最重要）

### 檔案用途
追蹤整個模擬過程中，代理人在不同交通模式間的分佈變化。

### 欄位說明

| 欄位 | 含義 | 單位 | 說明 |
|------|------|------|------|
| `iteration` | 模擬迭代次數 | 整數 | 0 = 初始狀態，1+ = 代理人進行了N次決策調整 |
| `car` | 開車模式比例 | 百分比（0-1） | 選擇自駕車的代理人佔總代理人的百分比 |
| `pt` | 大眾運輸比例 | 百分比（0-1） | 選擇捷運/公車的代理人佔總代理人的百分比 |
| `walk` | 步行模式比例 | 百分比（0-1） | 選擇步行的代理人佔總代理人的百分比 |

### 實際案例解釋

```
iteration;car;pt;walk
0;0.410;0.451;0.139       ← 初始狀態：
1;0.410;0.451;0.139       ← 迭代1：模式比例未變（早期收斂）
```

**情景 A: 理想收斂（模式探索充分）**
```
iteration;car;pt;walk
0;0.50;0.30;0.20          ← 初始：50%自駕、30%捷運、20%步行
1;0.45;0.40;0.15          ← 迭代1：更多人改用捷運
2;0.40;0.45;0.15          ← 迭代2：繼續微調
3;0.38;0.47;0.15          ← 迭代3：趨於平衡（收斂）
```
**說明**: 模式比例在迭代過程中有明顯變化，代表代理人正在探索並學習最適合的交通模式。

**情景 B: 早期收斂（問題）**
```
iteration;car;pt;walk
0;0.410;0.451;0.139       ← 初始
1;0.410;0.451;0.139       ← 迭代1：完全相同（不好！）
2;0.410;0.451;0.139       ← 迭代2：還是相同
```
**說明**: 模式分佈迭代0到迭代1沒有變化，代表代理人沒有進行模式探索，過早決定了交通方式。

### 診斷檢查清單

- ✅ **好現象**：迭代1-5之間，car/pt的比例至少變化 ±5%
- ❌ **壞現象**：所有迭代的數值完全相同，表示 `SubtourModeChoice` 未啟用或權重太低
- ⚠️ **警示**：迭代15+後仍在變動超過 ±10%，可能模式尚未收斂

### 使用 modestats.csv 改進模型

1. **如果模式比例不變** → 增加 `SubtourModeChoice` 策略權重（已在 config.xml 中配置為 0.20）
2. **如果某模式完全消失** → 檢查該模式的計分參數（walk/car/pt marginalUtilityOfTraveling）
3. **如果收斂太快** → 增加 `maxAgentPlanMemorySize` 以保留更多備選方案（已設為 15）

---

## 2. `scorestats.csv` - 代理人滿意度評分統計

### 檔案用途
追蹤代理人計畫的評分（效用值）如何隨迭代變化。評分越高代表代理人越滿意。

### 欄位說明

| 欄位 | 含義 | 單位 | 說明 |
|------|------|------|------|
| `iteration` | 模擬迭代次數 | 整數 | 0, 1, 2, ... |
| `avg_executed` | 已執行計畫的平均評分 | 分數 | 代理人實際執行計畫的平均效用 |
| `avg_worst` | 最差計畫的平均評分 | 分數 | 每個代理人記憶中，最糟糕計畫的平均評分 |
| `avg_average` | 平均計畫的平均評分 | 分數 | 每個代理人所有計畫的平均評分 |
| `avg_best` | 最佳計畫的平均評分 | 分數 | 每個代理人記憶中，最佳計畫的平均評分 |

### 實際案例解釋

```
iteration;avg_executed;avg_worst;avg_average;avg_best
0;71.39;71.39;71.39;71.39      ← 初始：只有1個計畫
1;71.39;71.39;71.39;71.40      ← 迭代1：開始探索，best 略高於 executed
```

**情景：代理人學習過程**

假設一個住在信義區、上班到北投的上班族：

```
迭代 0（初始計畫）：
  已執行：自駕 [評分: 60] ← 實際選擇
  最佳：自駕 [評分: 60]

迭代 1（嘗試新方案）：
  已執行：自駕 [評分: 60]（昨天的習慣）
  最佳：捷運 [評分: 75]（新發現！更省時間和金錢）
  最差：自駕塞車 [評分: 45]

迭代 2（轉向最佳）：
  已執行：捷運 [評分: 75]（改用了！）
  最佳：捷運 [評分: 75]

迭代 3（微調最佳）：
  已執行：捷運+走路 [評分: 78]（加上散步到站）
  最佳：捷運+走路 [評分: 78]
```

### 診斷檢查清單

- ✅ **好現象**：`avg_best` > `avg_executed`，代表代理人有更好的選擇方案
- ✅ **好現象**：`avg_executed` 逐漸上升（迭代5+後），代表代理人在學習
- ❌ **壞現象**：所有四個欄位完全相同且不變，代表沒有探索
- ❌ **壞現象**：`avg_best` 和 `avg_worst` 差距很大（>50），代表模式多樣性太高，可能配置有問題

### 重要閾值

- **評分相對變化** ±2-5% = 正常收斂
- **評分相對變化** >10% = 模式還在探索，未完全收斂
- **avg_best - avg_executed** = 0 = 最優狀態，代理人已找到最佳計畫

---

## 3. `ph_modestats.csv` - 人小時統計（Person-Hours by Mode）

### 檔案用途
統計所有代理人在各交通模式上花費的總時間（單位：人小時）。

### 欄位說明

| 欄位 | 含義 | 單位 | 說明 |
|------|------|------|------|
| `Iteration` | 模擬迭代次數 | 整數 | 0, 1, 2, ... |
| `car_travel` | 自駕行進時間 | 人小時 | 所有代理人開車的總時間 |
| `car_wait` | 自駕等待時間 | 人小時 | 所有代理人找停車位等的時間 |
| `pt_travel` | 捷運行進時間 | 人小時 | 所有代理人搭乘大眾運輸的總時間 |
| `pt_wait` | 捷運等待時間 | 人小時 | 所有代理人等車的時間 |
| `walk_travel` | 步行時間 | 人小時 | 所有代理人走路的總時間 |
| `walk_wait` | 步行等待時間 | 人小時 | 步行無等待時間，此欄通常為0 |

### 實際案例解釋

```
Iteration;car_travel;car_wait;pt_travel;pt_wait;walk_travel;walk_wait
0;14;0;31;6;84;0
```

**情景：100人一天的出行統計**

假設100個代理人，模擬一天：

- **自駕（car）**：
  - 14人小時行進 = 14人平均開30分鐘 OR 7人開1小時
  - 0人小時等待 = 停車位充足，無需排隊

- **捷運（pt）**：
  - 31人小時搭乘 = 31人平均搭乘30分鐘 OR 15人搭1小時
  - 6人小時等待 = 平均每人等車6分鐘（很合理）

- **步行（walk）**：
  - 84人小時走路 = 最多人選擇步行！
  - 代表短距離通勤居多

### 診斷檢查清單

- ✅ **好現象**：walk_travel 很高（>50人小時），代表短距離規劃合理
- ✅ **好現象**：pt_wait 與 pt_travel 比例合理（<20%等待）
- ❌ **壞現象**：car_wait 很高（>car_travel），代表交通堵塞嚴重
- ❌ **壞現象**：pt_wait 遠高於 pt_travel，代表班次不足或轉乘時間過長

---

## 4. `pkm_modestats.csv` - 每公里人數統計（Person-Kilometer by Mode）

### 檔案用途
統計所有代理人在各交通模式上行進的總距離（單位：人公里，PKM）。

### 欄位說明

| 欄位 | 含義 | 單位 | 說明 |
|------|------|------|------|
| `Iteration` | 模擬迭代次數 | 整數 | 0, 1, 2, ... |
| `car` | 自駕總距離 | 人公里 | 所有人開車行進的總公里數 |
| `pt` | 捷運總距離 | 人公里 | 所有人搭乘大眾運輸的總公里數 |
| `walk` | 步行總距離 | 人公里 | 所有人走路的總公里數 |

### 實際案例解釋

```
Iteration;car;pt;walk
0;650;920;389
```

**情景：100人一天的里程統計**

- **自駕（car）**：650人公里
  - 平均每人開6.5公里
  - 代表40人開 16.25公里 OR 10人開 65公里

- **捷運（pt）**：920人公里 ✅ **最多！**
  - 平均每人搭9.2公里
  - 代表從北區到南區的長距離通勤

- **步行（walk）**：389人公里
  - 平均每人走3.89公里
  - 相對少，代表只有短距離步行

### PKM vs PH（人小時）對比

```
模式   | 人小時 | 人公里 | 平均速度
-------|--------|--------|----------
自駕   | 14     | 650    | 46 km/h（市區合理）
捷運   | 31     | 920    | 30 km/h（含等車）
步行   | 84     | 389    | 4.6 km/h（步行速度）
```

### 診斷檢查清單

- ✅ **好現象**：pt 的人公里最多（長距離通勤）
- ✅ **好現象**：walk 的人公里較少（短距離）
- ❌ **壞現象**：car 的人公里遠高於 pt，代表自駕模式仍主導
- ❌ **壞現象**：迭代間 PKM 完全不變，代表沒有模式切換

---

## 5. `traveldistancestats.csv` - 距離統計

### 檔案用途
統計代理人單次行程（leg）和整個行程（trip）的平均距離。

### 欄位說明

| 欄位 | 含義 | 單位 | 說明 |
|------|------|------|------|
| `ITERATION` | 模擬迭代次數 | 整數 | 0, 1, 2, ... |
| `avg. Average Leg distance` | 單段行程平均距離 | 公里 | 每個 leg（activity間的移動）的平均距離 |
| `avg. Average Trip distance` | 整個行程平均距離 | 公里 | 每個 trip（home→work→home）的平均距離 |

### 實際案例解釋

```
ITERATION;avg. Average Leg distance;avg. Average Trip distance
0;2350.8;6846.2
1;2351.5;6848.3
```

**情景：代理人行程結構**

一個代理人的典型「行程」(Trip)：
```
home (信義區)
  ↓ leg1: 2.5 km
work (內湖區)
  ↓ leg2: 3.2 km
lunch (南京復興)
  ↓ leg3: 1.1 km
home (信義區)

整個Trip = 6.8 km
平均Leg = (2.5 + 3.2 + 1.1) / 3 = 2.27 km
```

### Leg vs Trip 的區別

| 概念 | 範例 | 用途 |
|------|------|------|
| **Leg** | home→work, work→lunch | 評估單段交通的效率 |
| **Trip** | home→work→lunch→home | 評估整日行程的合理性 |

### 診斷檢查清單

- ✅ **好現象**：Leg距離 1-5 km（市區合理）
- ✅ **好現象**：Trip距離 5-15 km（一日行程合理）
- ❌ **壞現象**：Leg距離 >10 km，代表目的地選擇距離太遠
- ❌ **壞現象**：迭代間距離大幅變化（>20%），代表路由算法有問題

---

## 6. `stopwatch.csv` - 模擬效能統計

### 檔案用途
記錄模擬的各個階段耗時，用於診斷模擬瓶頸。

### 主要欄位說明

| 步驟 | 含義 | 典型耗時 |
|-----|------|---------|
| `iteration` | 迭代號 | - |
| `replanning` | 代理人重新規劃路線時間 | <1秒 |
| `mobsim` | 交通模擬主引擎運行時間 | 1-10秒（最耗時） |
| `scoring` | 評分計算時間 | <1秒 |
| `iteration` | 整個迭代總耗時 | 2-15秒 |

### 實際案例解釋

```
iteration;...;mobsim;...;iteration (耗時)
0;...;00:00:03;...;00:00:04
1;...;00:00:03;...;00:00:03
```

**情景：模擬效能分析**

- **迭代0**：總耗時 4秒
  - Mobsim（交通模擬）：3秒 = 75% ✅ 合理
  - 其他（規劃、評分）：1秒 = 25%

- **迭代1**：總耗時 3秒
  - Mobsim：3秒
  - Mobsim 耗時保持穩定 ✅ 代表代理人數穩定

### 診斷檢查清單

- ✅ **好現象**：每迭代耗時 2-5秒（100代理人）
- ✅ **好現象**：mobsim 耗時佔 60-80%（符合預期）
- ⚠️ **警示**：mobsim 耗時 >10秒，代理人可能過多或網路過複雜
- ❌ **壞現象**：迭代間耗時波動很大（>100%），代表有記憶洩漏或其他問題

### 計算模擬總耗時

```
假設最後迭代（iteration 15）耗時 4秒：

- 4秒 × 16迭代 = 64秒 ≈ 1分鐘

這是可接受的效能
```

---

## 完整診斷工作流

### Step 1: 檢查 `modestats.csv`

```bash
# 檢查模式是否在迭代間有變化
head -5 scenarios/equil/output/modestats.csv
```

- ✅ 若car/pt在迭代1-5間變化 ±5-10% → **正常**，代理人在探索
- ❌ 若完全相同 → **早期收斂**，需增加 SubtourModeChoice 權重

### Step 2: 檢查 `scorestats.csv`

```bash
tail -5 scenarios/equil/output/scorestats.csv
```

- ✅ 若 `avg_executed` 逐漸上升 → **學習中**
- ❌ 若平坦 → **沒有改進**，檢查計分參數

### Step 3: 檢查 `stopwatch.csv` 最後幾行

```bash
tail -3 scenarios/equil/output/stopwatch.csv
```

- ✅ 耗時 <5秒/迭代 → **正常效能**
- ⚠️ 耗時 5-10秒 → **可能優化空間**
- ❌ 耗時 >10秒 → **效能瓶頸**

### Step 4: 檢查 `ph_modestats.csv` 和 `pkm_modestats.csv`

```bash
tail -3 scenarios/equil/output/ph_modestats.csv
tail -3 scenarios/equil/output/pkm_modestats.csv
```

- 若 walk 佔比太高（>60%） → 檢查目的地選擇是否過近
- 若 pt 數值為0 → 檢查 transitSchedule 是否正確加載

---

## 常見問題與解決

### 問題 1: 模式比例完全不變

**症狀**：`modestats.csv` 中所有迭代的 car/pt/walk 完全相同

**原因**：
1. `SubtourModeChoice` 未啟用或權重過低
2. 計分參數使某模式無競爭力

**解決**：
- ✅ 已在 `config.xml` 中將 `SubtourModeChoice` 權重設為 0.20
- 運行新模擬並檢查迭代1-5的變化

### 問題 2: 評分沒有改進

**症狀**：`scorestats.csv` 中 `avg_executed` 平坦不變

**原因**：
1. 初始計畫已是局部最優
2. 代理人未進行有效探索

**解決**：
- 檢查初始計畫（population.xml）是否過於優化
- 增加 `maxAgentPlanMemorySize` 保留更多備選方案（已設為15）

### 問題 3: PT 轉乘未被使用

**症狀**：`pt_wait` 為0，或 PT 選擇率遠低於預期

**原因**：
1. `utilityOfLineSwitch` 設置過高，懲罰轉乘
2. 轉乘時間配置不合理

**解決**：
- ✅ 已將 `utilityOfLineSwitch` 設為 0.0
- ✅ 已將 `transferPenaltyBaseCost` 和 `transferPenaltyCostPerTravelTimeHour` 設為 0.0
- 檢查 PT 代理是否有多個行程段（已在生成中強制3-4個活動）

---

## 總結

| 檔案 | 主要用途 | 優先度 |
|-----|---------|--------|
| **modestats.csv** | 模式選擇演化 | ⭐⭐⭐ 最重要 |
| **scorestats.csv** | 代理人滿意度 | ⭐⭐⭐ 最重要 |
| **ph_modestats.csv** | 時間分配 | ⭐⭐ 重要 |
| **pkm_modestats.csv** | 距離分配 | ⭐⭐ 重要 |
| **traveldistancestats.csv** | 行程距離檢查 | ⭐ 參考用 |
| **stopwatch.csv** | 效能監控 | ⭐ 參考用 |

**建議閱讀順序**：
1. 先看 `modestats.csv` 確認模式是否在探索
2. 再看 `scorestats.csv` 確認是否在改進
3. 最後看 `ph_modestats.csv` 和 `pkm_modestats.csv` 驗證結果的合理性

---

## 7. `modeChoiceCoverage1x.txt` - 模式選擇覆蓋率（一般變化）

### 檔案用途
追蹤有多少比例的代理人曾經嘗試過特定交通模式（不論是否最終選擇）。

### 欄位說明

| 欄位 | 含義 | 範圍 | 說明 |
|------|------|------|------|
| `Iteration` | 迭代次數 | 0-15 | 模擬進度 |
| `car` | 嘗試過car的代理比例 | 0-1 | 累積嘗試過的代理人百分比 |
| `pt` | 嘗試過pt的代理比例 | 0-1 | 累積嘗試過的代理人百分比 |
| `walk` | 嘗試過walk的代理比例 | 0-1 | 累積嘗試過的代理人百分比 |

### 實際案例數據

```
Iteration	car	pt	walk
0	0.323	0.473	0.204      ← 初始：32%試car、47%試pt、20%試walk
5	0.517	0.602	0.525      ← 迭代5：51%試car、60%試pt、52%試walk
15	0.840	0.765	0.824      ← 迭代15：84%試car、76%試pt、82%試walk
```

**解釋**：
- 從迭代 0 到迭代 15，嘗試各模式的代理人比例大幅增加
- 84% 的代理試過開車（相比初始 32% 增加 52個百分點）
- 這表示 replanning 策略有效地讓代理探索多種模式

### 診斷檢查清單

- ✅ **好現象**：覆蓋率持續上升，最終接近 80-90%
- ✅ **好現象**：三種模式覆蓋率都有增加
- ❌ **壞現象**：覆蓋率停滯不變（<50% at iter 15）
- ❌ **壞現象**：某模式覆蓋率始終 <30%，可能該模式不可用

---

## 8. `modeChoiceCoverage5x.txt` - 模式選擇覆蓋率（5倍變化）

### 檔案用途
追蹤有多少比例的代理人至少經歷了 5 次該交通模式的嘗試或改變。

### 實際案例數據

```
Iteration	car	pt	walk
0	0.000	0.000	0.000      ← 迭代0：無人有5次變化
4	0.145	0.245	0.119      ← 迭代4：14.5%的car試者有5次變化
15	0.419	0.581	0.297      ← 迭代15：41.9%的car、58.1%的pt嘗試者有5次變化
```

**解釋**：
- 前 4 個迭代都是 0（沒有代理有 5 倍變化）
- 迭代 4+ 開始出現 5 倍變化的代理
- PT 在迭代 15 達到 58.1%（最多代理經歷多次 PT 模式改變）
- 這表示代理在積極探索 PT 選項

### 診斷檢查清單

- ✅ **好現象**：迭代 5+ 後出現非零值
- ✅ **好現象**：迭代 15 時，至少有 40% 代理有 5 倍探索
- ❌ **壞現象**：迭代 15 仍為 0 或 <10%，說明探索不足
- ⚠️ **警示**：PT 的 5x 覆蓋率遠高於 car/walk，可能 PT 更易吸引探索

---

## 9. `modeChoiceCoverage10x.txt` - 模式選擇覆蓋率（10倍變化）

### 檔案用途
追蹤有多少比例的代理人經歷了至少 10 次該交通模式的嘗試或改變。

### 實際案例數據

```
Iteration	car	pt	walk
0-8	0.000	0.000	0.000      ← 迭代0-8：無代理有10倍變化
9	0.075	0.067	0.070      ← 迭代9：首次出現（<8%）
15	0.196	0.377	0.152      ← 迭代15：19.6%car、37.7%pt、15.2%walk
```

**解釋**：
- 10 倍變化是最激進的探索指標
- 只有在迭代 9 後才開始出現
- PT 在迭代 15 達到 37.7%（代表著 37% 的代理至少試過 10 次 PT 變化）
- 這表示部分代理在模式間頻繁切換，尋找最適選擇

### 診斷檢查清單

- ✅ **好現象**：迭代 9+ 開始有非零值
- ✅ **好現象**：PT 的 10x 覆蓋率最高（37.7%），說明 PT 選擇複雜
- ❌ **壞現象**：迭代 15 仍全為 0，代表沒有激進探索
- ⚠️ **解釋**：10x 覆蓋率通常較低（10-40%），這是正常的

---

## 實際案例分析：模式探索旅程

### 假設代理 pt_agent_01 的迭代過程

```
迭代 0 (初始)：
  計劃：home → (PT) → work
  評分：20.5
  覆蓋率貢獻：+1 to PT

迭代 1 (首次探索)：
  ChangeExpBeta: 選擇了不同的計劃變體
  計劃1：home → (PT) → work          [評分 20.5]
  計劃2：home → (WALK) → work        [評分 18.2，新嘗試]
  覆蓋率貢獻：+1 to Walk

迭代 2-4 (繼續探索)：
  SubtourModeChoice: 試著改變交通模式
  計劃1：home → (PT) → work          [評分 20.5]
  計劃2：home → (CAR) → work         [評分 22.3，更好！]
  覆蓋率貢獻：+1 to Car，Car 5x 計數 +1

迭代 5+ (收斂)：
  代理逐漸偏好 CAR（評分最高）
  但仍保留 PT 計劃作為備選
  最終：CAR 被選中最頻繁
```

**覆蓋率軌跡**：
- 迭代 0：car 0%, pt 1/100=1%, walk 0%
- 迭代 4：car 已達 25% (已有25人試過car)
- 迭代 15：car 84%, pt 76%, walk 82%

---

## 綜合案例：完整模擬結果解讀

### 基於實際 2025-11-12 運行的數據

**配置**：
- 100 個代理（50 PT, 40 car, 10 walk）
- 15 迭代
- Replanning 策略：ChangeExpBeta (0.50) + ReRoute (0.20) + SubtourModeChoice (0.20) + Explore (0.10)

**結果分析**：

#### 1. 模式選擇變化（modestats.csv）
```
迭代 0：car 32.3%, pt 47.3%, walk 20.4%
迭代 15：car 28.9%, pt 47.5%, walk 23.5%
變化：car -3.4%, pt +0.2%, walk +3.1%
```
✅ **評估**：模式分佈有變化（walk +3% 對應覆蓋率 +40%），說明探索有效

#### 2. 代理滿意度（scorestats.csv）
```
迭代 0：avg_executed 20.57, avg_best 20.57, avg_worst 20.57 (無選擇)
迭代 15：avg_executed 43.24, avg_best 70.51, avg_worst -80.27
改進：+111% (43.24 vs 20.57)
```
✅ **評估**：代理在學習和改進，已執行計劃改進 111%

#### 3. 時間分配（ph_modestats.csv）
```
迭代 0：car 14h, pt 48h, walk 152h
迭代 15：car 14h, pt 45h, walk 171h
結論：walk 主導（占67%）, PT 次之 (17%), car最少 (5%)
```
✅ **評估**：短距離步行為主（代理選擇在附近活動），符合臺北都市特性

#### 4. 距離分配（pkm_modestats.csv）
```
迭代 0：car 665 PKM, pt 1377 PKM, walk 693 PKM
迭代 15：car 636 PKM, pt 1283 PKM, walk 793 PKM
結論：PT 主導長距離（62%), car 占 31%, walk 占 38%
```
✅ **評估**：代理合理選擇了模式（遠距用PT，近距用walk）

#### 5. 模式覆蓋率演化
```
迭代 1x 覆蓋率 (普遍覆蓋)：
  迭代 0：32.3% car, 47.3% pt, 20.4% walk
  迭代 15：84.0% car, 76.5% pt, 82.4% walk

迭代 5x 覆蓋率 (深度探索)：
  迭代 0：0% (無人有5次變化)
  迭代 15：41.9% car, 58.1% pt, 29.7% walk

迭代 10x 覆蓋率 (激進探索)：
  迭代 0-8：0% (無代理達到10次變化)
  迭代 15：19.6% car, 37.7% pt, 15.2% walk
```

**整體解讀**：✅ 成功的模式探索！
- 84% 的代理至少試過一種異於初始的模式
- 58% 的代理在 PT 上有深度探索（≥5次變化）
- 37.7% 的代理在 PT 上進行激進探索（≥10次變化）

### 性能評估（stopwatch.csv）

```
迭代 0：總耗時 6秒 (mobsim 4秒, scoring 1秒, 其他 1秒)
迭代 15：總耗時 3秒 (mobsim 3秒, scoring <1秒, 其他 <1秒)
```

✅ **評估**：效能優良，每迭代平均 3.5 秒，100 代理共耗時約 56 秒（<1分鐘）

---

## 快速診斷決策樹

```
看到不同數據？按此樹診斷：

├─ modestats.csv 模式比例完全不變？
│  ├─ YES → ❌ 早期收斂，需增加 SubtourModeChoice 權重
│  └─ NO → 繼續
│
├─ modeChoiceCoverage1x.txt 迭代15 < 50%？
│  ├─ YES → ⚠️ 代理探索不足，考慮增加迭代數
│  └─ NO → 繼續
│
├─ scorestats.csv avg_best 完全不變？
│  ├─ YES → ❌ 沒有計劃改進，檢查計分參數
│  └─ NO → ✅ 代理在學習
│
├─ stopwatch.csv mobsim > 10秒/迭代？
│  ├─ YES → ⚠️ 效能瓶頸，減少代理數或簡化網路
│  └─ NO → ✅ 效能正常
│
└─ pkm_modestats.csv 某模式PKM = 0？
   ├─ YES → ❌ 該模式不可用，檢查網路和計分參數
   └─ NO → ✅ 所有模式都被使用
```
